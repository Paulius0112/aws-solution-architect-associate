# S3

In a newly created S3 bucket, everything // every additional option is turned off by default. Also, no bucket policy exists.

__S3 types__ are - 
1. *Amazon S3 Standard*
    - Offers high durability, availability and performance object storage for frequently accessed data.
    - S3 storage classes can be configured at the object level and a single bucket can contain objects stored accross S3 Standard, Intelligent-Tiering, Standard-IA and S3 One Zone-IA
    - Low latency and high throughput performance
    - Designed durability of 99.999999999% of objects across multiple Availability Zones
    - Resilient against events that impact an entire Availability Zone
    - Designed for 99.99% availability over a given year
    - Suppoers SSL for data in transit and encryption of data at rest
    - S3 Lifecycle management for automatic migration of objects to other S3 Storage Classes  
2. *Amazon S3 Intelligent-Tiering*
    - Is the first cloud storage that automatically reduces your storage costs on a granular object level by automatically moving data to the most cost-effective access tier based on access frequency, without performance impact, retrieval fees, or operational overhead.
    - Frequent, Infrequent, and Archive Instant Access tiers have the same low-latency and high-throughput performance of S3 Standard
    - The Infrequent Access tier saves up to 40% on storage costs
    - The Archive Instant Access tier saves up to 68% on storage costs
    - Opt-in asynchronous archive capabilities for objects that become rarely accessed
    - Deep Archive Access tier has the same performance as Glacier Deep Archive and saves up to 95% for rarely accessed objects
    - Designed for durability of 99.999999999% of objects across multiple Availability Zones and for 99.9% availability over a given year
    - Small monthly monitoring and auto tiering charge
    - Objects smaller than 128KB can be stored in S3 Intelligent-Tiering but will always be charged at the Frequent Access tier rates, and are not charged the monitoring and automation charge.
3. *Amazon S3 Standard-Infrequent Access (S3 Standard-IA)*
    - S3 Standard-IA is for data that is accessed less frequently, but requires rapid access when needed.
    - Same low latency and high throughput performance of S3 Standard
    - Designed for durability of 99.999999999% of objects across multiple Availability Zones
    - Resilient against events that impact an entire Availability Zone
    - Data is resilient in the event of one entire Availability Zone destruction
    - Designed for 99.9% availability over a given year
    - Supports SSL for data in transit and encryption of data at rest
    - S3 Lifecycle management for automatic migration of objects to other S3 Storage Classes
4. *One Zone IA*
    - For data that is accessed less frequently, but requires rapid access when needed. S3 One Zone-IA stores data in a single AZ and costs 20% less than S3 Standard-IA. S3 One Zone-IA is ideal for customers who want a lower-cost option for infrequently accessed data but do not require the availability and resilience of S3 Standard or S3 Standard-IA. It’s a good choice for storing secondary backup copies of on-premises data or easily re-creatable data, cost-effective storage for data that is replicated from another AWS Region using S3 Cross-Region Replication.
    - same low latency and high throughput performance of S3 Standard
    - Designed for durability of 99.999999999% of objects in a single Availability Zone
    - Designed for 99.5% availability over a given year
    - Backed with the Amazon S3 Service Level Agreement for availability
    - Supports SSL for data in transit and encryption of data at rest
    - S3 Lifecycle management for automatic migration of objects to other S3 Storage Classes
5. *Glacier*
    - is an archive storage class that delivers the lowest-cost storage for long-lived data that is rarely accessed and requires retrieval in milliseconds.
    - You can save up to 68% on storage costs compared to using the S3 Standard-Infrequent Access (S3 Standard-IA) storage class, when your data is accessed once per quarter. Delivers the fastest access to archive storage, with the same throughput and milliseconds access as the S3 Standard and S3 Standard-IA storage classes. **S3 Glacier Instant Retrieval**  is ideal for archive data that needs immediate access, such as medical images, news media assets, or user-generated content archives.
    - Data retrieval in milliseconds with the same performance as S3 Standard
    - Designed for durability of 99.999999999% of objects across multiple Availability Zones
    - Data is resilient in the event of the destruction of one entire Availability Zone
    - Designed for 99.9% data availability in a given year
    - 128 KB minimum object size
    - Backed with the Amazon S3 Service Level Agreement for availability
    - S3 PUT API for direct uploads to S3 Glacier Instant Retrieval, and S3 Lifecycle management for automatic migration of objects
6. *Glacier Deep Archive*
    - Designed for durability of 99.999999999% of objects across multiple Availability Zones
    - Lowest cost storage class designed for long-term retention of data that will be retained for 7-10 years
    - Ideal alternative to magnetic tape libraries
    - Retrieval time within 12 hours
    - S3 PUT API for direct uploads to S3 Glacier Deep Archive, and S3 Lifecycle management for automatic migration of objects

__S3 encryptions__ —
- Bucket by default is *private*. Access control can be set using *Bucket policies (bucket level) * and *access control list (individual objects)*
- Encryption can be    
    - *In Transit* - achieved by SSL/TLS
    - *At Rest*
        - **Server side** - acheived by S3 Managed Keys (SSE-S3), AWS Key Management Service, Managed Keys - SSE-KMS, Customer Provided Keys (SSE-C)
            - SSE-S3: Data and master keys managed by S3.
            - SSE-C: The user manages the encryption keys.
            - SSE-KMS: AWS manages the data key, the user manages the master key.
        - **Client Side Encryption** - encrypt yourself and upload to S3
- Individual files or the whole bucket can be encrypted. More efficient is to encrypt the whole bucket
- S3 can be configured to create access logs which log all requests made to the S3 bucket. This can be sent
    to other buckets

__Versioning__
1. Once enabled, it cannot be disabled. Only suspended
2. Versioning has MFA Delete capability
3. Great backup tool
4. Integrates with lifecycle rules 
5. Each new version is initialy private. We need to make each public one by one
6. We can delete version individually, but the main file will only be suspended
7. Stores all versions of an object (including all writes and even if you delete an object)

__Lifecycle notes__
- Automates moving your objects between the different storage tiers
- Can be used in conjuction with versioning (Current and previous versions)
- Objects must stay in storage tier minimum of 30 days before transition

__AWS S3 performance__

- 3,500 requests per second to PUT/COPY/POST/DELETE data
- 5,500 requests per second to retrieve data per prefix
- The more prefixes we have, the better performance we can achieve. For example, if you use two prefixes, you can achieve 11000 requests per second.
- If using KMS server side encryption, they have requests quotas, which can limit S3 performance
- *Multipart uploads* - increase performance when uploading files to S3. 
    1. Uploads single object as a set of parts. Once parts are uploaded, S3 assembles these parts and creates an object
    2. Should be used for any files over 100MB and must be used for any file over 5 GB

- *S3 byte-range fetches* - increase performance when downloading large files from S3

__S3 bucket properties__ are —
1. Versioning
2. Server access logging
3. Static website hosting
4. Object level logging // Essentially CloudTrail
5. Transfer acceleration
6. Events


__Object level properties__—  
Metadata and Storage class are object level properties. All object level properties are
1. Storage class
2. Encryption
3. Metadata
4. Tags
5. *Object lock* - implement WORM(Write Once Read Many) to prevent objects from being deleted or modified for a fixed amount of time or indefinitely
    - **Governance mode** - users can't overwrite or delete an object version or alter its lock settings unless they have special permissions. Protect against most users, but privileged users can still delete
    - **Compliance mode** - can't be overwriten or delete by any user (including root user) for the duration of the reterntion period
        - ***Retention period*** - period that protects an object version for a fixed amount of time. S3 stores a timestamp in the object version's metadata to indicate expirity date. After the expiry objects can be deleted/modified unless *legal hold* is placed on the object version
        - ***Legal hold*** - doesn't have retention period and remains in effect until removed. Can be placed/removed by any user who has the s3:PutObjectLegalHold
6. *Glacier vault lock* - allows to easility deploy and enforce compliance controls for individual S3 Glacier vaults with a vault lock policy. However, will not be able to change.

__DELETE operation__ does not keep a copy unless you have versioning enabled. From the docs
> The DELETE operation removes the null version (if there is one) of an object and inserts a delete marker, which becomes the current version of the object. If there isn't a null version, Amazon S3 does not remove any objects. 

S3 is a __managed service__. It can't be part of a VPC.

__S3 object metadata__—
1. System metadata
2. User-defined metadata

User defined metadatas must start with `x-amz-meta`.

When you enable logging on a bucket, the console both enables logging on the source bucket and adds a grant in the target bucket's access control list (ACL) granting write permission to the Log Delivery Group.

__S3 bucket endpoints formats__ —
1. http://bucket.s3.amazonaws.com
2. http://bucket.s3.aws-region.amazonaws.com
3. http://bucket.s3-aws-region.amazonaws.com
4. http://s3.amazonaws.com/bucket
5. http://s3.aws-region.amazonaws.com/bucket
6. http://s3-aws-region.amazonaws.com/bucket

__Update__ — AWS will stop supporting the URL path format for buckets created after September 30, 2020. Read [this](https://aws.amazon.com/blogs/aws/amazon-s3-path-deprecation-plan-the-rest-of-the-story/) for details.

__Object sizes__ —
S3 can store objects of size 0 bytes to 5 TB.
A single PUT can transfer 5 GB max. For files larger than 100MB, multipart upload is recommended.

__AWS Organisations__
- Account management service that enables you to consolidate multiple AWS accounts into an organization and manage centraly

__Consolidated Billing__
- One bill per AWS account
- Very easy to track charges and allocate costs
- Volume pricing discount

__Cross-region replication__ requires that versioning be enabled on both the source bucket and the destination bucket.
- Also, public permissions on the file replicates across the regions
- Files in an existing bucket are not replicated automatically 
- Deleting files will not be replicated

__AWS Glacier archive retrieval__ options —
- Expedited: Costly, 1-5 minutes.
- Standard: Default, 3-5 hours.
- Bulk: Cheapest, 5-12 hours.

To increase performance, we can __prefix each object name with a hash key__ along with the current date. But, according to the new S3 performance announcement, this is __not needed anymore__.

__Increasing performance in S3__ —
- If workload is mainly GET requests, integrate Cloudfront with S3.
- If workload consists of PUT requests, use S3 transfer acceleration.

In the __CORS__ configuration, the __exact URLs__ must be added, with the correct protocol, i.e. __http vs https__.

__S3__ does not support `OPTIONS`, `CONNECT` and `TRACE` __methods__. 

To make sure that S3 objects are only accessible from Cloudfront, create an __Origin Access Identity (OAI) for Cloudfront__ and grant access to the objects to that OAI.

__Cloudfront__
- *Edge location* - location where the content will be cached. This is separate to AWS region/AZ
- *Origin* - files and CDN will distribute. Can be S3, EC2, ELB, Route53
- Can be used as Web Distribution or *RTMP* (for media streaming)
- Edge locations are not read only. We can perform PUT operations as well
- Objects will be cached for TTL
- Cache invalidation charged by each invalidation
- **Custom origin** can point to on-premise server and can cache **dynamic content**
    - If on-premise server is connected using **direct connect**, additional performance can be created

__Signed URLs__ (secures content so that only the poeple you authorize are able to access it)
- One signed URL for individual file
- One signed cookie for multiple files
- We need to attach policy, with can have *URL expiration*, *IP ranges*, *Trusted signers (which AWS accounts can create signed URLs)*
- Doesn't allow to access s3 directly. Need to go through CloudFront to get a signed request
If your origin is EC2, use CloudFront

__S3 Signed URL__
- Issues a request as the IAM user who creates the presigned URL (you have the same permissions as the creator of bucket)
- Limited lifetime
- Can access S3 directly
- Use if your origin is S3 and you only have one file



We can create __event notification in S3__ to __invoke lambda__ function.

__Customer managed S3 encryption workflow__ —  
Generate a data key using Customer managed CMK. Encrypt data using data key and delete data key. Store encrypted data key and data in S3 buckets. For decryption, use CMK to decrypt data key into plain text and then decrypt data using plain text data key.

__Provisioned capacity__ should be used when we want to guarantee the availability of fast expedited retrieval from S3 Glacier within minutes.

For __S3 static website hosting__, the default provided __URL__ is https://bucket-name.s3-website-aws-region.amazonaws.com.

S3 server side encryption uses __AES 256__.

S3 __event notification targets__ —

- SQS
- SNS
- Lambda

__S3 Cross Account Access__
- Using Bucket policies and IAM (Across the entire bucket). Programmatic access only
- Using Bucket ACLs and IAM (Individual objects). Programmatic access only
- Cross-account IAM Roles. Programmatical and Console access

__S3 select__
Enables applications to retrieve only a subset of data from an object by using simple SQL expressions. By retrieving only the required data, you can achieve drastic performance increases

An 80 TB __Snowball__ appliance and 100 TB Snowball Edge appliance only have 72 TB and 83 TB of __usable capacity__ respectively. 

__Snowball__
- It is a petabyte-scale data transport solution that uses secure appliances to transfer large amounts of data into and out of AWS
- Solves the problem of large-scale data transfers including high network costs, long transfer times, security concerns.
- Provides simple, fast, secure data transfer and can be as little as one-fifth the cost of high-speed internet
- Comes in either 50TB or 80TB. Snowball Edge comes with 100TB data transfer
- Snowball Edge allows to move large amounts of data into and out of AWS, as a temporary storage tier for large local datasets, or to support local workloads in remote or offline locations

For __static website hosting__ with S3, the name of the bucket must be the same as the domain or subdomain name.

__Preventing accidental deletion__ of S3 objects —

- Enable versioning
- Enable MFA delete

__S3 object lock__
- Allows to store objects using a *write once, read many (WORM)* model. 
- Helps prevent objects from being deleted or modified for a fixed amount of time
- There are several modes:
    - *Governance Mode* - protect objects against being deleted by most users, byt you can still grant some users permission to alter the retention settings or delete
    - *Compliance Mode* - protected object version can't be overwritten or deleted by any user (including the root)
- *Retention period* - protects an object version for a fixed amount of time

__S3 DataSync__
- Used to move large amounts of data from on-premises to AWS
- Replications can be done hourly, daily or weekly 
- Install the DataSync Agent to start the replication

__Athena__
- Interactive query service which enables you to analyse and query data located in S3 using standard SQL
- Serverless, nothing to provision, pay per queue / per TB scanned
- No need to set up complex Extract/Transform/Load (ETL) processes
- Works directly with data stored in S3
- Where can be used?
    - To query log files stored in S3
    - Generate business reports on data stored in S3
    - Analyse AWS cost and usage reports
    - Run queries on click-stream data
- Amazon Athena is an interactive query service that makes it easy to analyse data in Amazon S3, using standard SQL commands. It will work with a number of data formats including "JSON", "Apache Parquet", "Apache ORC" amongst others, but "XML" is not a format that is supported.

__Macie__
- *PII* - personally identifiable information used to establish an individual's identity
- Macie - is a security service which used Machine Learning and Natural Language Processing to discover, clasiffy and protect sensitive data stored in S3
- Dashboards, reporting and alerts
- Works directly with daa stored in S3
- Can also analyze CloudTrail logs
- Great for preventing ID theft

